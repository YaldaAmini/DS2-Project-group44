{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 44 Final Project CS109B - Twitter\n",
    "## Tweet Database Generator\n",
    "\n",
    "\n",
    "\n",
    "**Spring 2019**<br/>\n",
    "**Authors**: Daniel Barjum, Yalda Amini, João Araújo\n",
    "\n",
    "**Description**\n",
    "This python code generates a single database of all the tweets obtained from various data sources. We generate a single database as it is needed in order to be passed onto our neural network. The tweets database comes from researcher's database that we were granted access on behalf of the researchers to use for this project. Information on the dataset can be obtained here: http://mib.projects.iit.cnr.it/dataset.html\n",
    "\n",
    "The tweets database contains multiple information for each tweet. Some data is useful, some is not. This code analyzes this data and removes any variables that we deemed were not necesarry for use in predicting whether an acocunt is a bot or not.\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths to files where data is stored\n",
    "\n",
    "path = os.getcwd()+'/data/datasets_full/'\n",
    "\n",
    "folders = ['genuine_accounts/', 'social_spambots_1/', 'social_spambots_2/', \n",
    "           'social_spambots_3/', 'traditional_spambots_1/', 'traditional_spambots_2/',\n",
    "           'traditional_spambots_3/', 'traditional_spambots_4/', 'fake_followers/']\n",
    "\n",
    "file_names = ['users.csv', 'tweets.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data containes differing types variable types for some columns which difficults and slows the process of reading into a pandas dataframe. Here we define how some columns should be read into pandas in order to avoid warning and speed up the process a bit. \n",
    "\n",
    "Some columns, although numerical in nature, were coerced into strings as they are more useful in that manner. For example, columns that have a user id were changed into a string instead of an int or float as we can use this number if we need to request information from Twitter's API which would prefer to see strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define datatype for some columns to speed up process and avoid warnings when reading raw data\n",
    "type_dic = {'user_id': str, 'id': str, 'contributors': str,\n",
    "            'crawled_at': str, 'in_reply_to_screen_name': str,\n",
    "            'place': str, 'retweeted_status_id': str, \n",
    "            'in_reply_to_screen_name': str, 'in_reply_to_status_id': str,\n",
    "            'in_reply_to_user_id': str, 'updated': str, 'created_at': str}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in databases and append each one into a single database. Show number of datapoints being read from each database and final count of observations.\n",
    "\n",
    "The try-except is there to catch any errors from reading the files or if files do not exits. We discovered that some files were missing from the researchers data, so we just ignore these files during the reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File genuine_accounts/tweets.csv has shape of: (2839362, 25)\n",
      "File social_spambots_1/tweets.csv has shape of: (1610034, 25)\n",
      "File social_spambots_2/tweets.csv has shape of: (428542, 25)\n",
      "File social_spambots_3/tweets.csv has shape of: (1418557, 25)\n",
      "File traditional_spambots_1/tweets.csv has shape of: (145094, 25)\n",
      "File traditional_spambots_2/tweets.csv not found, ignoring\n",
      "File traditional_spambots_3/tweets.csv not found, ignoring\n",
      "File traditional_spambots_4/tweets.csv not found, ignoring\n",
      "File fake_followers/tweets.csv has shape of: (196027, 23)\n",
      "final tweet database is of shape (6637616, 25)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for f in folders:\n",
    "    try:\n",
    "        temp_df = pd.read_csv(path+f+file_names[1], dtype=type_dic)\n",
    "        print('File {0} has shape of: {1}'.format(f+file_names[1], temp_df.shape))\n",
    "        df = df.append(temp_df, ignore_index=True, sort=True)\n",
    "    except FileNotFoundError:\n",
    "        print('File {:s} not found, ignoring'.format(f+file_names[1])) \n",
    "\n",
    "print('final tweet database is of shape {0}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that some columns contain no information at all. This next section of code checks for columns that contain no information and drops these columns from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns only contained nulls: ['favorited', 'geo', 'retweeted'], these have been dropped\n"
     ]
    }
   ],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "empty_cols = []\n",
    "for c in df.select_dtypes(include=numerics).columns:\n",
    "    if len(np.isnan(df[c].unique()))==1 & np.isnan(df[c].unique())[0]:\n",
    "        empty_cols.append(c)\n",
    "\n",
    "df = df.drop(empty_cols, axis=1)\n",
    "print('The following columns only contained nulls: {0}, these have been dropped'.format(empty_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6637616, 22)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>truncated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.637615e+06</td>\n",
       "      <td>6.637615e+06</td>\n",
       "      <td>6.637615e+06</td>\n",
       "      <td>6.637615e+06</td>\n",
       "      <td>26812.0</td>\n",
       "      <td>6.637615e+06</td>\n",
       "      <td>6.637615e+06</td>\n",
       "      <td>753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.352860e+00</td>\n",
       "      <td>1.561749e-01</td>\n",
       "      <td>3.908975e-01</td>\n",
       "      <td>2.003855e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.848357e-02</td>\n",
       "      <td>3.832842e+02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.313966e+02</td>\n",
       "      <td>5.913658e-01</td>\n",
       "      <td>7.311432e-01</td>\n",
       "      <td>4.062391e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.474201e+01</td>\n",
       "      <td>1.100351e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.353000e+05</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.751600e+04</td>\n",
       "      <td>3.350111e+06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorite_count  num_hashtags  num_mentions      num_urls  \\\n",
       "count    6.637615e+06  6.637615e+06  6.637615e+06  6.637615e+06   \n",
       "mean     2.352860e+00  1.561749e-01  3.908975e-01  2.003855e-01   \n",
       "std      3.313966e+02  5.913658e-01  7.311432e-01  4.062391e-01   \n",
       "min     -1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%      0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
       "max      1.353000e+05  2.800000e+01  1.900000e+01  6.000000e+00   \n",
       "\n",
       "       possibly_sensitive   reply_count  retweet_count  truncated  \n",
       "count             26812.0  6.637615e+06   6.637615e+06      753.0  \n",
       "mean                  1.0  2.848357e-02   3.832842e+02        1.0  \n",
       "std                   0.0  1.474201e+01   1.100351e+04        0.0  \n",
       "min                   1.0  0.000000e+00   0.000000e+00        1.0  \n",
       "25%                   1.0  0.000000e+00   0.000000e+00        1.0  \n",
       "50%                   1.0  0.000000e+00   0.000000e+00        1.0  \n",
       "75%                   1.0  0.000000e+00   0.000000e+00        1.0  \n",
       "max                   1.0  2.751600e+04   3.350111e+06        1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we notice from the describe above that some columns have very few observations (possibly_sensitive and truncated). Reading Twitter's API pages about these two variables, we deemed that it was safe to drop this variable for analysis as 1) it has few observations, and 2) the values are not very useful as they proxy other variables.\n",
    "\n",
    "See https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html for information about variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['possibly_sensitive','truncated'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>crawled_at</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>place</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>updated</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>Fri May 01 00:18:11 +0000 2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>593932392663912449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>593932168524533760</td>\n",
       "      <td>&lt;a href=\"http://tapbots.com/tweetbot\" rel=\"nof...</td>\n",
       "      <td>RT @morningJewshow: Speaking about Jews and co...</td>\n",
       "      <td>2015-05-01 02:18:11</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>678033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>Thu Apr 30 21:50:52 +0000 2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>593895316719423488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>This age/face recognition thing..no reason pla...</td>\n",
       "      <td>2015-04-30 23:50:52</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>678033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>Thu Apr 30 20:52:32 +0000 2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>593880638069018624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>Only upside of the moment I can think of is th...</td>\n",
       "      <td>2015-04-30 22:52:32</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>678033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>Thu Apr 30 18:42:40 +0000 2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>593847955536252928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://tapbots.com/tweetbot\" rel=\"nof...</td>\n",
       "      <td>If you're going to think about+create experien...</td>\n",
       "      <td>2015-04-30 20:42:40</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>678033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>Thu Apr 30 18:41:36 +0000 2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>593847687847350272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://tapbots.com/tweetbot\" rel=\"nof...</td>\n",
       "      <td>Watching a thread on FB about possible future ...</td>\n",
       "      <td>2015-04-30 20:41:36</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>678033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  contributors           crawled_at                      created_at  \\\n",
       "0          NaN  2015-05-01 12:57:19  Fri May 01 00:18:11 +0000 2015   \n",
       "1          NaN  2015-05-01 12:57:19  Thu Apr 30 21:50:52 +0000 2015   \n",
       "2          NaN  2015-05-01 12:57:19  Thu Apr 30 20:52:32 +0000 2015   \n",
       "3          NaN  2015-05-01 12:57:19  Thu Apr 30 18:42:40 +0000 2015   \n",
       "4          NaN  2015-05-01 12:57:19  Thu Apr 30 18:41:36 +0000 2015   \n",
       "\n",
       "   favorite_count                  id in_reply_to_screen_name  \\\n",
       "0             0.0  593932392663912449                     NaN   \n",
       "1             0.0  593895316719423488                     NaN   \n",
       "2             0.0  593880638069018624                     NaN   \n",
       "3             1.0  593847955536252928                     NaN   \n",
       "4             0.0  593847687847350272                     NaN   \n",
       "\n",
       "  in_reply_to_status_id in_reply_to_user_id  num_hashtags  num_mentions  \\\n",
       "0                     0                   0           0.0           1.0   \n",
       "1                     0                   0           0.0           0.0   \n",
       "2                     0                   0           2.0           0.0   \n",
       "3                     0                   0           2.0           0.0   \n",
       "4                     0                   0           0.0           0.0   \n",
       "\n",
       "   num_urls place  reply_count  retweet_count retweeted_status_id  \\\n",
       "0       0.0   NaN          0.0            1.0  593932168524533760   \n",
       "1       0.0   NaN          0.0            0.0                   0   \n",
       "2       0.0   NaN          0.0            0.0                   0   \n",
       "3       0.0   NaN          0.0            2.0                   0   \n",
       "4       0.0   NaN          0.0            0.0                   0   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://tapbots.com/tweetbot\" rel=\"nof...   \n",
       "1  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "2  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "3  <a href=\"http://tapbots.com/tweetbot\" rel=\"nof...   \n",
       "4  <a href=\"http://tapbots.com/tweetbot\" rel=\"nof...   \n",
       "\n",
       "                                                text            timestamp  \\\n",
       "0  RT @morningJewshow: Speaking about Jews and co...  2015-05-01 02:18:11   \n",
       "1  This age/face recognition thing..no reason pla...  2015-04-30 23:50:52   \n",
       "2  Only upside of the moment I can think of is th...  2015-04-30 22:52:32   \n",
       "3  If you're going to think about+create experien...  2015-04-30 20:42:40   \n",
       "4  Watching a thread on FB about possible future ...  2015-04-30 20:41:36   \n",
       "\n",
       "               updated user_id  \n",
       "0  2015-05-01 12:57:19  678033  \n",
       "1  2015-05-01 12:57:19  678033  \n",
       "2  2015-05-01 12:57:19  678033  \n",
       "3  2015-05-01 12:57:19  678033  \n",
       "4  2015-05-01 12:57:19  678033  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also notice that columns 'contributors', 'in_reply_to_screen_name', and 'place' appear to have lots of NaNs, let's look at the columns to see if they contain useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column contributors has 1 unique values:\n",
      "[nan]\n",
      "\n",
      "column in_reply_to_screen_name has 271336 unique values:\n",
      "[nan 'thelancearthur' 'wkamaubell' ... 'QueenBitchEnt' 'QBLilKim'\n",
      " 'TokyozFinest1']\n",
      "\n",
      "column place has 3191 unique values:\n",
      "[nan 'Tucson, AZ' 'Casas Adobes, AZ' ... 'Cártama, Malaga'\n",
      " 'Chalco, Messico' 'Universiti Multimedia, Bukit Baru']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in ['contributors', 'in_reply_to_screen_name', 'place']:\n",
    "    print('column {:s} has {:d} unique values:'.format(c, len(df[c].unique())))\n",
    "    print(df[c].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, seems like 'contributors' column is empty so we will remove this column. The other two columns do seem to contain information about tweets and we will keep them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('contributors', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if some columns that should contain a numerical value contain any Null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column crawled_at has 196028 null values\n",
      "column created_at has 1 null values\n",
      "column favorite_count has 1 null values\n",
      "column in_reply_to_screen_name has 5598482 null values\n",
      "column in_reply_to_status_id has 1 null values\n",
      "column in_reply_to_user_id has 1 null values\n",
      "column num_hashtags has 1 null values\n",
      "column num_mentions has 1 null values\n",
      "column num_urls has 1 null values\n",
      "column place has 6508965 null values\n",
      "column reply_count has 1 null values\n",
      "column retweet_count has 1 null values\n",
      "column retweeted_status_id has 196028 null values\n",
      "column source has 73 null values\n",
      "column text has 13007 null values\n",
      "column timestamp has 1 null values\n",
      "column updated has 196028 null values\n",
      "column user_id has 1 null values\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    if df[c].isna().sum() > 0:\n",
    "        print('column {:s} has {:d} null values'.format(c, df[c].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice a few things here. There are several columns with only 1 null value, and some columns with many null values. Let's explore further to determine if we can fill this missing data or if we can drop them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first check all columns that contain only 1 null, maybe they all point the the exact same observation. if this is the case, then we could simply delete this observation and we would only loose a single data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2839361 is where the null is for column created_at\n",
      "index 2839361 is where the null is for column favorite_count\n",
      "index 2839361 is where the null is for column in_reply_to_status_id\n",
      "index 2839361 is where the null is for column in_reply_to_user_id\n",
      "index 2839361 is where the null is for column num_hashtags\n",
      "index 2839361 is where the null is for column num_mentions\n",
      "index 2839361 is where the null is for column num_urls\n",
      "index 2839361 is where the null is for column reply_count\n",
      "index 2839361 is where the null is for column retweet_count\n",
      "index 2839361 is where the null is for column timestamp\n",
      "index 2839361 is where the null is for column user_id\n"
     ]
    }
   ],
   "source": [
    "single_nulls = ['created_at', 'favorite_count', 'in_reply_to_status_id',\n",
    "                'in_reply_to_user_id', 'num_hashtags', 'num_mentions', \n",
    "                'num_urls', 'reply_count', 'retweet_count', 'timestamp', 'user_id']\n",
    "\n",
    "for c in single_nulls:\n",
    "    print('index {:d} is where the null is for column {:s}'.format(df.loc[df[c].isna()].index[0],c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as expected, they all correspond to same observation, so lets delete this observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.loc[df.created_at.isna()].index[0], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns 'crawled_at'and 'updated' were columns added by the researchers. They used twitter crawlers to collect information for this database. These columns do not belong to information about users that can be collected through Twitter's API, hence we will drop these two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['crawled_at', 'updated'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column in_reply_to_screen_name has 5598481 null values\n",
      "column place has 6508964 null values\n",
      "column retweeted_status_id has 196027 null values\n",
      "column source has 72 null values\n",
      "column text has 13006 null values\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    if df[c].isna().sum() > 0:\n",
    "        print('column {:s} has {:d} null values'.format(c, df[c].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
